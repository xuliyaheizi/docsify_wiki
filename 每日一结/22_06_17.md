# 22年6月17日小记

## docker容器跨主机通信

`Overlay 网络`是为特定目的在物理（底层）网络之上创建的逻辑网络。`Docker` 可以创建容器之间的 `Overlay 网络`，从而实现跨主机的容器之间的沟通。也就是说，只要几台物理机之间本身是可以通信的，那么只要在这些机器上建立好一个 `Overlay 网络`把需要相互通讯的容器，直接部署在这个网络之上，最终的效果就类似于将这些容器部署在同一台物理机一样，进行**任意通信**啦。比如说我们需要实现一个 `Elasticsearch` 集群，那么我们只需要把各个节点部署在预先创建好的一个 `Overlay 网络`上就可以实现通信啦。

为什么 `Overlay 网络`就可以实现多台物理机之间的网络互通呢？实际上它是在 `Docker` 集群节点间的加入了一层虚拟网络，它有独立的虚拟网段。`Docker` 容器发送的请求，会先发送到**虚拟子网**，再由**虚拟子网**包装为宿主机的**真实网址**进行发送。

而今天要介绍的 `Docker Swarm`，则是 `Docker Overlay` 网络的一种简易实现方式，它是 `Docker` 开发的容器集群管理工具， 与 `Docker API` 兼容性很好。并且 `Linux` 中安装了 `Docker`,也默认会安装 `Swarm`。 因此，在这里，我们采用 `Swarm` 实现 集群间的网络通信

说明：使用 Swarm 建立跨主机的网络，实际上总共分为如下几步：

1. 在 **manager** 创建一个 `Swarm` 集群
2. 将其他集群分别加进来
3. 在 **manager** 创建一个 `Overlay` 网络
4. 启动各个容器时，指定这个 `Overlay` 网络

```shell
#在 manager 节点创建 Swarm 集群
docker swarm init --advertise-addr=192.168.10.20

docker swarm join --token SWMTKN-1-3qimfd2bnfsyzbm7gyeasuocwh1ytfs7u543nyyp3n7g670piv-ecd3nio1ki27w89uchv1dkdnz 8.134.120.71:2377

docker run -d --name consul --restart always -p 8050:8400 -p 8051:8500 -p 8052:53/udp -h consul progrium/consul -server -bootstrap -ui-dir /ui

ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --cluster-store=consul://zhulinz.top:8051 --cluster-advertise=ens33:2375

systemctl daemon-reload
systemctl restart docker

docker run --name dkmaster --hostname dkmaster -d --net=sharednet -p 8210:22 -p 8211:8020 -p 8212:8042 -p 8214:9864 -p 8215:50070 -p 8218:8088  zhulins/myhadoop

docker run --name dknode2 --hostname dknode2 -d --net=sharednet -p 8410:22 -p 8411:8020 -p 8412:8042 -p 8413:9864 -p 8415:50070 -p 8418:8088 zhulins/myhadoop

docker network create --driver overlay --attachable --subnet=192.168.30.0/16 --gateway=192.168.30.2  --opt com.docker.network.driver.mtu=1200 hadoopnet
```

## Maven中引入CDH依赖

```xml
<repositories>
	<repository>
		<id>cloudera-releases</id>
		<url>https://repository.cloudera.com/artifactory/cloudera-repos</url>
	<releases>
		<enabled>true</enabled>
	</releases>
	<snapshots>
		<enabled>false</enabled>
	</snapshots>
	</repository>
</repositories>
```

## Hadoop集群部署docker

错误：Unexpected EOF while trying to read response from server

流水线中的第一个 DN 负载超标，导致流水线建立失败

```java
2022-06-17 22:58:50,925 INFO [org.apache.hadoop.hdfs.DataStreamer] - Exception in createBlockOutputStream blk_1073741825_1001
 java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:446)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1762)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1679)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
2022-06-17 22:58:50,929 WARN [org.apache.hadoop.hdfs.DataStreamer] - Abandoning BP-226454236-172.172.0.10-1655477708338:blk_1073741825_1001
 2022-06-17 22:58:50,952 WARN [org.apache.hadoop.hdfs.DataStreamer] - Excluding datanode DatanodeInfoWithStorage[172.172.0.11:9866,DS-6bf0f4b4-22ff-4520-8057-e6304dbbe7ec,DISK]
 2022-06-17 22:59:06,288 INFO [org.apache.hadoop.hdfs.DataStreamer] - Exception in createBlockOutputStream blk_1073741826_1002
 java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:446)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1762)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1679)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
2022-06-17 22:59:06,288 WARN [org.apache.hadoop.hdfs.DataStreamer] - Abandoning BP-226454236-172.172.0.10-1655477708338:blk_1073741826_1002
 2022-06-17 22:59:06,298 WARN [org.apache.hadoop.hdfs.DataStreamer] - Excluding datanode DatanodeInfoWithStorage[172.172.0.10:9866,DS-cfe06bc1-6d7b-430d-b0bb-962cd211d0cb,DISK]
 2022-06-17 22:59:21,648 INFO [org.apache.hadoop.hdfs.DataStreamer] - Exception in createBlockOutputStream blk_1073741827_1003
 java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:446)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1762)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1679)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
2022-06-17 22:59:21,649 WARN [org.apache.hadoop.hdfs.DataStreamer] - Abandoning BP-226454236-172.172.0.10-1655477708338:blk_1073741827_1003
 2022-06-17 22:59:21,665 WARN [org.apache.hadoop.hdfs.DataStreamer] - Excluding datanode DatanodeInfoWithStorage[172.172.0.13:9866,DS-137866f7-c636-4a5d-89a7-1f68e0ce9f9d,DISK]
 2022-06-17 22:59:37,008 INFO [org.apache.hadoop.hdfs.DataStreamer] - Exception in createBlockOutputStream blk_1073741828_1004
 java.io.EOFException: Unexpected EOF while trying to read response from server
	at org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:446)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1762)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1679)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
2022-06-17 22:59:37,008 WARN [org.apache.hadoop.hdfs.DataStreamer] - Abandoning BP-226454236-172.172.0.10-1655477708338:blk_1073741828_1004
 2022-06-17 22:59:37,022 WARN [org.apache.hadoop.hdfs.DataStreamer] - Excluding datanode DatanodeInfoWithStorage[172.172.0.12:9866,DS-cd8750e1-d3e7-423b-849e-d1dc8cca8688,DISK]
 2022-06-17 22:59:37,022 WARN [org.apache.hadoop.hdfs.DataStreamer] - DataStreamer Exception
 java.io.IOException: Unable to create new block.
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1694)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
2022-06-17 22:59:37,026 WARN [org.apache.hadoop.hdfs.DataStreamer] - Could not get block locations. Source file "/home/zhulin/5_计算属性的补充.wmv" - Aborting...block==null
 
java.io.IOException: Could not get block locations. Source file "/home/zhulin/5_计算属性的补充.wmv" - Aborting...block==null

	at org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1477)
	at org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1256)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:667)
```

**总结：**可能原因是Hadoop集群基于Docker部署未开放完程序需要的端口，解决方案是使PC端口能与docker容器直接通信，在本地直接访问容器节点的ip地址。详情见[6-18小记](/每日一结/22_06_18)。
