# 22年6月24日小记

## 项目技术点说明

<img src="https://knowledgeimagebed.oss-cn-hangzhou.aliyuncs.com/img/image-20220624115059752.png" alt="image-20220624115059752" width="67%;" />





1. sink组: 负载均衡

2. 多source汇总. 

Ganglia: 任务执行情况监控   -> JVM

3. 自定义 Source  
     自定义 Sink. 

4. 过滤器  -> 扩展. 

## 云盘项目扩展

1. node1:请安装 mysql, ngix, tomcat

2. 请配置 flume 采集 nginx, tomcat运行日志，入库到 hdfs中. 

3. 请配置好云盘项目的 日志, 发布你云盘项目,打成 jar包，运行起来, 
     用flume采集此项目的日志。 

4. 请将云盘项目动静分离. 静态资源 html, css, js放到 nginx中， 后台部分打成jar独立运行，生成日志，
   由flume采集日志发到 hdfs 保存. 负载均衡

```
//jar包运行
java -jar cloudDisk.jar > cloudDisk.log &
```



### Hadoop上安装Tomcat

下载tomcat8.5解压并上传至 /usr/local/tomcat

![image-20220625113353903](https://knowledgeimagebed.oss-cn-hangzhou.aliyuncs.com/img/image-20220625113353903.png)

进入tomcat下的conf目录，修改tomcat-users.xml

```shell
cd /usr/local/tomcat/conf
vim tomcat-users.xml
#添加以下内容
<role rolename="admin-gui"/>
<role rolename="manager-gui"/>
<user username="admin" password="admin" roles="admin-gui,manager-gui"/>
```

配置Tomcat用户管理页的远程访问
cd /usr/localtomcat/webapps/manager/META-INF/context.xml
将下面内容注释掉。

![image-20220625113918529](https://knowledgeimagebed.oss-cn-hangzhou.aliyuncs.com/img/image-20220625113918529.png)

### hadoop上安装nginx

安装相关依赖包

```shell
sudo yum -y install openssl openssl-devel pcre pcre-devel zlib zlib-devel gcc gcc-c++
```

将nginx文件上传到 /tmp/nginx

```
Ngnix下载地址：http://nginx.org/en/download.html
```

进入nginx目录下，执行以下命令

```shell
./configure   --prefix=/usr/local/nginx

make && make install
```

启动nginx

```shell
在/opt/module/nginx/sbin目录下执行  ./nginx

#查看启动情况
ps -ef |grep nginx
```

### hadoop安装mysql

下载安装包，将压缩包上传至 /opt/mysql，并解压

```
https://dev.mysql.com/downloads/file/?id=511379

tar -xf mysql-8.0.29-1.el7.x86_64.rpm-bundle.tar
```

添加用户组

```
 groupadd mysql
 添加用户组
 
 useradd -g mysql mysql
 添加用户
 
 id mysql
 查看用户信息。
```

卸载MariaDB

```
rpm -qa | grep mariadb查询是否有该软件
如果有，就卸载：rpm -e mariadb-libs-这里是你的版本，如果不能卸载（或报错）则采用强制卸载：rpm -e --nodeps mariadb-libs-这里是你的版本
```

安装Mysql

```shell
rpm -ivh *.rpm
安装过程要按照如下顺序（必须）进行：

	 mysql-community-common-8.0.29-1.el7.x86_64.rpm
	 mysql-community-client-plugins-8.0.29-1.el7.x86_64.rpm
	 mysql-community-libs-8.0.29-1.el7.x86_64.rpm             --（依赖于common）
	 mysql-community-client-8.0.29-1.el7.x86_64.rpm          --（依赖于libs）
	 mysql-community-icu-data-files-8.0.29-1.el7.x86_64.rpm
	 mysql-community-server-8.0.29-1.el7.x86_64.rpm         --（依赖于client、common）
	按照以上顺序进行一个个的安装，脚本如下：
	
	rpm -ivh mysql-community-server-5.7.16-1.el7.x86_64.rpm
	
期间缺少啥组件，安装啥
libaio.so.1()(64bit) is needed by mysql-community-embedded-compat-8.0.29-1.el7.x86_64
yum -y install libaio

libnuma.so.1()(64bit) is needed by mysql-community-embedded-compat-8.0.29-1.el7.x86_64
yum -y install numactl
```

```
mysql安装软件在/usr/share/mysql目录下

Mysql数据库创建在/var/lib/mysql目录下
```

我们进入到mysql这个目录中，更改一下权限：

```shell
cd /usr/share/mysql/
chown -R mysql:mysql .
```

启动mysql

```
service mysqld restart

//登录
mysql
报错：ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: NO)  需添加权限

在/ect/my.cnf 的最后面加上一行：skip-grant-tables

service mysqld restart
```

初始化数据库

```shell
sudo mysqld --initialize --user=mysql
//查看临时生成的root用户密码
sudo cat /var/log/mysqld.log
//修改密码
mysql> set password = password("新密码");
```

### 配置Flume采集nginx运行日志收集到hdfs中

修改nginx配置

```shell
cd /usr/local/nginx/conf
vim nginx.conf
#将部分注释去掉
log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';
#修改日志名
		#开启
        access_log logs/access.log main;
        #access_log  logs/host.access.log  main;

#重启nginx
nginx -s reload
```

编写Flume配置

```shell
#新建flume配置目录
mkdir nginx
cd nginx
pwd  # /usr/local/flume/jobs/nginx
vim nginxlog-hdfs.conf
```

配置

```shell
#Agent配置
n1.sources=r1
n1.sinks=k1
n1.channels=c1

#配置Sources
n1.sources.r1.type=exec
n1.sources.r1.deserializer.outputCharset=UTF-8
n1.sources.r1.batchSize=10
n1.sources.r1.batchTimeout=2000

#配置需要监控的日志输出目录
n1.sources.r1.command=tail -F /usr/local/nginx/logs/access.log

#配置Sink
n1.sinks.k1.type=hdfs
#按天分区
n1.sinks.k1.hdfs.path=hdfs://master:8020/flume/nginxlogs/%Y-%m-%d
#文件名
n1.sinks.k1.hdfs.filePrefix=log-%Y-%m-%d-%H
n1.sinks.k1.hdfs.round=true
n1.sinks.k1.hdfs.roundValue=1
#指定每个HDFS块的最小配置数。如果没有指定，则来着类路径中的默认  Hadoop配置
n1.sinks.k1.hdfs.minBlockReplicas=1
n1.sinks.k1.hdfs.fileType=DataStream
#序列文件格式
n1.sinks.k1.hdfs.writeFormat=Text
#重新定义时间单位
n1.sinks.k1.hdfs.roundUnit=hour
#是否使用本地时间戳
n1.sinks.k1.hdfs.useLocalTimeStamp=true
#积攒多少个Event才flush到hdfs一次
n1.sinks.k1.hdfs.batchSize=100
#设置文件类型，可支持压缩
n1.sinks.k1.hdfs.fileType=DataStream
#多久生成一个新的文件
n1.sinks.k1.hdfs.rollInterval=600
#设置每个文件的滚动大小
n1.sinks.k1.hdfs.rollSize=134217700
#文件的滚动与Event数量无关
n1.sinks.k1.hdfs.rollCount=0

#配置Channel
n1.channels.c1.type=memory
n1.channels.c1.capacity=1000
n1.channels.c1.transactionCapacity=1000

#连接
n1.sources.r1.channels=c1
n1.sinks.k1.channel=c1
```

### 项目前端Nginx静态分离

上传静态文件

![image-20220625102646766](https://knowledgeimagebed.oss-cn-hangzhou.aliyuncs.com/img/image-20220625102646766.png)

配置nginx.conf

```shell
location /cloudDisk{
	root /home;
	index login.html login.htm;
}
```

### Nginx负载均衡配置

```shell
#服务器的集群  
upstream  cloud.com {  #服务器集群名字   
	server	master:8080	weight=1;#服务器配置   weight是权重的意思，权重越大，分配的概率越大。  
	server	node1:8080  weight=2;
    server	node2:8080	weight=2;
    server	node3:8080	weight=2;
} 

location /cloudDisk{
	root /home;
	index login.html login.htm;
	proxy_pass http://cloud.com/cloudDisk;  
	proxy_redirect default; 
}

```

### Flume采集Tomcat运行日志存入hdfs

```shell
t1.sources=r1
t1.sinks=k1
t1.channels=c1

#配置Sources
t1.sources.r1.type=exec
t1.sources.r1.command=tail -F /usr/local/tomcat/logs/localhost_access_log.txt
t1.sources.r1.shell=/bin/bash -c
t1.sources.r1.batchSize=10
t1.sources.r1.batchTimeout=2000

#配置Sink
t1.sinks.k1.type=hdfs
t1.sinks.k1.hdfs.path=hdfs://master:8020/flume/tomcat/%Y-%m-%d
t1.sinks.k1.hdfs.filePrefix=masterlog-%H-%M-%S
t1.sinks.k1.hdfs.round=true
t1.sinks.k1.hdfs.roundValue=1
#指定每个HDFS块的最小配置数。如果没有指定，则来着类路径中的默认  Hadoop配置
t1.sinks.k1.hdfs.minBlockReplicas=1
t1.sinks.k1.hdfs.fileType=DataStream
#序列文件格式
t1.sinks.k1.hdfs.writeFormat=Text
#重新定义时间单位
t1.sinks.k1.hdfs.roundUnit=hour
#是否使用本地时间戳
t1.sinks.k1.hdfs.useLocalTimeStamp=true
#积攒多少个Event才flush到hdfs一次
t1.sinks.k1.hdfs.batchSize=100
#设置文件类型，可支持压缩
t1.sinks.k1.hdfs.fileType=DataStream
#多久生成一个新的文件
t1.sinks.k1.hdfs.rollInterval=600
#设置每个文件的滚动大小
t1.sinks.k1.hdfs.rollSize=134217700
#文件的滚动与Event数量无关
t1.sinks.k1.hdfs.rollCount=0

#配置Channel
t1.channels.c1.type=memory
t1.channels.c1.capacity=1000
t1.channels.c1.transactionCapacity=1000

#连接
t1.sources.r1.channels=c1
t1.sinks.k1.channel=c1
```

## SpringBoot打包实现静态文件、配置文件、jar包分离

```xml
<plugins>
        <!--定义项目的编译环境-->
        <plugin>
            <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-compiler-plugin</artifactId>
            <configuration>
                <source>1.8</source>
                <target>1.8</target>
                <encoding>UTF-8</encoding>
            </configuration>
        </plugin>
        <!--maven的测试用例插件，建议跳过。-->
        <plugin>
            <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-surefire-plugin</artifactId>
            <configuration>
                <skip>true</skip>
            </configuration>
        </plugin>
        <!--这个是springboot的默认编译插件，他默认会把所有的文件打包成一个jar-->
        <plugin>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-maven-plugin</artifactId>
            <executions>
                <execution>
                    <goals>
                        <goal>repackage</goal>
                    </goals>
                </execution>
            </executions>
            <configuration>
                <mainClass>com.ruoyi.RuoYiApplication</mainClass>
                <fork>true</fork>
                <addResources>true</addResources>
                <outputDirectory>${project.build.directory}/jar</outputDirectory>
            </configuration>
        </plugin>
        <!-- 打JAR包 -->
        <plugin>
            <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-jar-plugin</artifactId>
            <configuration>
                <!-- 不打包资源文件（配置文件和依赖包分开） -->
                <excludes>
                    <exclude>*.yml</exclude>
                    <exclude>*.properties</exclude>
                    <exclude>mybatis/**</exclude>
                    <exclude>static/**</exclude>
                </excludes>
                <archive>
                    <manifest>
                        <addClasspath>true</addClasspath>
                        <!-- MANIFEST.MF 中 Class-Path 加入前缀 -->
                        <classpathPrefix>lib/</classpathPrefix>
                        <!-- jar包不包含唯一版本标识 -->
                        <useUniqueVersions>false</useUniqueVersions>
                        <!--指定入口类 -->
                        <mainClass>com.ruoyi.Application</mainClass>
                    </manifest>
                    <manifestEntries>
                        <!--MANIFEST.MF 中 Class-Path 加入资源文件目录 -->
                        <Class-Path>./config/</Class-Path>
                    </manifestEntries>
                </archive>
                <outputDirectory>${project.build.directory}</outputDirectory>
            </configuration>
        </plugin>
        <!-- 该插件的作用是用于复制依赖的jar包到指定的文件夹里 -->
        <plugin>
            <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-dependency-plugin</artifactId>
            <executions>
                <execution>
                    <id>copy-dependencies</id>
                    <phase>package</phase>
                    <goals>
                        <goal>copy-dependencies</goal>
                    </goals>
                    <configuration>
                        <outputDirectory>${project.build.directory}/lib/</outputDirectory>
                    </configuration>
                </execution>
            </executions>
        </plugin>

        <!-- 该插件的作用是用于复制指定的文件 -->
        <plugin>
            <artifactId>maven-resources-plugin</artifactId>
            <executions>
                <execution> <!-- 复制配置文件 -->
                    <id>copy-resources</id>
                    <phase>package</phase>
                    <goals>
                        <goal>copy-resources</goal>
                    </goals>
                    <configuration>
                        <resources>
                            <resource>
                                <directory>src/main/resources</directory>
                                <includes>
                                    <include>*.yml</include>
                                    <include>*.properties</include>
                                    <include>mybatis/**</include>
                                    <include>static/**</include>
                                </includes>
                            </resource>
                        </resources>
                        <outputDirectory>${project.build.directory}/config</outputDirectory>
                    </configuration>
                </execution>
            </executions>
        </plugin>
    </plugins>
```

### Flume收集cloudDisk运行日志存入

```shell
d1.sources=r1
d1.sinks=k1
d1.channels=c1

#配置Sources
d1.sources.r1.type=exec
d1.sources.r1.command=tail -F /opt/cloudDisk/cloudDisk.log
d1.sources.r1.shell=/bin/bash -c
d1.sources.r1.batchSize=10
d1.sources.r1.batchTimeout=2000

#配置Sink
d1.sinks.k1.type=hdfs
d1.sinks.k1.hdfs.path=hdfs://master:8020/flume/tomcat/%Y-%m-%d
d1.sinks.k1.hdfs.filePrefix=cloudDiskNode1log-%H-%M-%S
d1.sinks.k1.hdfs.round=true
d1.sinks.k1.hdfs.roundValue=1
#指定每个HDFS块的最小配置数。如果没有指定，则来着类路径中的默认  Hadoop配置
d1.sinks.k1.hdfs.minBlockReplicas=1
d1.sinks.k1.hdfs.fileType=DataStream
#序列文件格式
d1.sinks.k1.hdfs.writeFormat=Text
#重新定义时间单位
d1.sinks.k1.hdfs.roundUnit=hour
#是否使用本地时间戳
d1.sinks.k1.hdfs.useLocalTimeStamp=true
#积攒多少个Event才flush到hdfs一次
d1.sinks.k1.hdfs.batchSize=100
#设置文件类型，可支持压缩
d1.sinks.k1.hdfs.fileType=DataStream
#多久生成一个新的文件
d1.sinks.k1.hdfs.rollInterval=600
#设置每个文件的滚动大小
d1.sinks.k1.hdfs.rollSize=134217700
#文件的滚动与Event数量无关
d1.sinks.k1.hdfs.rollCount=0

#配置Channel
d1.channels.c1.type=memory
d1.channels.c1.capacity=1000
d1.channels.c1.transactionCapacity=1000

#连接
d1.sources.r1.channels=c1
d1.sinks.k1.channel=c1

#后台进程运行
flume-ng agent --conf conf/ --conf-file cloudDiskLogs-hdfs.conf --name d1 &
```

### 编写启动node1、node2、node3节点cloudDisk项目和Flume监听日志脚本

```shell
#!/bin/bash 
 
if [ $# -lt 1 ] 
then 
    echo "No Args Input..." 
    exit ; 
fi 
 
case $1 in
"start")
	echo ======================= "启动cloudDisk项目" =======================
	echo "----------------------node1----------------------"
	ssh node1 "java -jar /opt/cloudDisk/cloudDisk.jar > /opt/cloudDisk/cloudDisk.log &"
	ssh node1 "flume-ng agent --conf conf/ --conf-file /usr/local/flume/jobs/cloudDiskLog/cloudDiskLogs-hdfs.conf --name d1 &"
	echo "---------------------ndoe2---------------------"
	ssh node2 "java -jar /opt/cloudDisk/cloudDisk.jar > /opt/cloudDisk/cloudDisk.log &"
	ssh node2 "flume-ng agent --conf conf/ --conf-file /usr/local/flume/jobs/cloudDiskLog/cloudDiskLogs-hdfs.conf --name d2 &"
	echo "---------------------ndoe3---------------------"
	ssh node3 "java -jar /opt/cloudDisk/cloudDisk.jar > /opt/cloudDisk/cloudDisk.log &"
	ssh node3 "flume-ng agent --conf conf/ --conf-file /usr/local/flume/jobs/cloudDiskLog/cloudDiskLogs-hdfs.conf --name d3 &"
;;
*)
	echo "input args error..."
;;
esac
```

