# 22年6月29日小记

## Sqoop连接mysql数据导入hdfs报错

```shell
#命令
sqoop import --connect jdbc:mysql://zhulinz.top:3306/testsqoop?serverTimezone=UTC --username zhulin -P --table project --target-dir /mysql/project --direct --delete-target-dir

#报错信息
2022-06-29 09:24:21,648 INFO mapreduce.Job:  map 33% reduce 0%
2022-06-29 09:24:22,659 INFO mapreduce.Job:  map 67% reduce 0%
2022-06-29 09:24:23,671 INFO mapreduce.Job:  map 100% reduce 0%
2022-06-29 09:24:30,730 INFO mapreduce.Job: Job job_1656465572952_0001 failed with state FAILED due to: Task failed task_1656465572952_0001_m_000000
Job failed as tasks failed. failedMaps:1 failedReduces:0 killedMaps:0 killedReduces: 0

2022-06-29 09:24:34,249 INFO mapreduce.Job: Counters: 12
	Job Counters 
		Failed map tasks=10
		Killed map tasks=2
		Launched map tasks=12
		Other local map tasks=12
		Total time spent by all maps in occupied slots (ms)=328682
		Total time spent by all reduces in occupied slots (ms)=0
		Total time spent by all map tasks (ms)=328682
		Total vcore-milliseconds taken by all map tasks=328682
		Total megabyte-milliseconds taken by all map tasks=336570368
	Map-Reduce Framework
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
2022-06-29 09:24:34,287 WARN mapreduce.Counters: Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
2022-06-29 09:24:34,294 INFO mapreduce.ImportJobBase: Transferred 0 bytes in 190.1152 seconds (0 bytes/sec)
2022-06-29 09:24:34,297 INFO mapreduce.ImportJobBase: Retrieved 0 records.
2022-06-29 09:24:34,301 ERROR tool.ImportTool: Import failed: Import job failed!
```

## MapReduce内存过小报错

```shell
#报错信息
[2022-06-29 16:25:45.392]Container [pid=4690,containerID=container_1656490964696_0001_01_000002] is running 347900416B beyond the 'VIRTUAL' memory limit. Current usage: 347.8 MB of 1 GB physical memory used; 2.4 GB of 2.1 GB virtual memory used. Killing container.
Dump of the process-tree for container_1656490964696_0001_01_000002 :
	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE
	|- 4690 4688 4690 4690 (bash) 0 0 9797632 133 /bin/bash -c /usr/local/jdk1.8/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN   -Xmx820m -Djava.io.tmpdir=/opt/hadoopdata/nm-local-dir/usercache/root/appcache/application_1656490964696_0001/container_1656490964696_0001_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/usr/local/hadoop/logs/userlogs/application_1656490964696_0001/container_1656490964696_0001_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 172.168.0.11 34963 attempt_1656490964696_0001_m_000000_0 2 1>/usr/local/hadoop/logs/userlogs/application_1656490964696_0001/container_1656490964696_0001_01_000002/stdout 2>/usr/local/hadoop/logs/userlogs/application_1656490964696_0001/container_1656490964696_0001_01_000002/stderr  
	|- 4699 4690 4690 4690 (java) 654 306 2592960512 88913 /usr/local/jdk1.8/bin/java -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=WARN -Xmx820m -Djava.io.tmpdir=/opt/hadoopdata/nm-local-dir/usercache/root/appcache/application_1656490964696_0001/container_1656490964696_0001_01_000002/tmp -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/usr/local/hadoop/logs/userlogs/application_1656490964696_0001/container_1656490964696_0001_01_000002 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA -Dhadoop.root.logfile=syslog org.apache.hadoop.mapred.YarnChild 172.168.0.11 34963 attempt_1656490964696_0001_m_000000_0 2 

[2022-06-29 16:25:52.938]Container killed on request. Exit code is 143
[2022-06-29 16:25:52.976]Container exited with a non-zero exit code 143. 
```

```shell
#原因：由于yarn的内存分配出现了问题
#解决办法：修改yarn-site.xml文件配置(添加下面的内容)
<property>
	<name>yarn.nodemanager.vmem-check-enabled</name>
	<value>false</value>
</property>
```

