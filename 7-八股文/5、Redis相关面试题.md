# Redis相关面试题

## 1、为什么要使用缓存？

使用缓存主要是为了**提升读写性能**。在实际业务情景下，更多的是为了提升读性能，带来`更好的性能`，带来`更高的并发量`。由于`Redis`的读写性能比`Mysql`好的多，可以把`Mysql`中的`热点数据缓存`到`Redis`中，提升读取性能，同时减轻Mysql的读写压力。

## 2、Redis的好处？

- `读取速度快`：数据存储在内存中。
- 支持`多种数据结构`：包括`String（字符串）`、`list（链表）`、`set（集合）`、`zset（有序集合）`、`hash（哈希类型）`等。
- 支持`事务`，且操作`遵守原子性`，即对数据的操作要么都执行，要么都不支持。
- 还拥有其他丰富的功能，`队列`、`主从复制`、`集群`、`数据持久化`等。

## 3、什么是Redis？

Redis 是一个开源（BSD 许可）、基于`内存`、支持`多种数据结构`的存储系统，可以作为`数据库`、`缓存`和`消息中间件`。它支持的数据结构有`字符串（strings）`、`哈希（hashes）`、`列表（lists）`、`集合（sets）`、`有序集合（sorted sets）`等，除此之外还支持 `bitmaps`、`hyperloglogs `和`地理空间（geospatial ）索引半径查询`等功能。它内置了主从复制（Replication）、LUA 脚本（Lua scripting）、LRU 驱动事件（LRU eviction）、事务（Transactions）和不同级别的磁盘持久化（persistence）功能，并通过 Redis 哨兵（哨兵）和集群（Cluster）保证缓存的高可用性（High availability）。

Redis是一种基于`内存`的数据库，`对数据的读写操作都是在内存中完成的`，因此读写速度非常快，常用于`缓存`、`消息队列`、`分布式锁`等场景。

## 4、为什么使用Redis而不是Memcache呢？

- `Redis`和`Memcache`都是将`数据存放在内存中`，都是`内存数据库`。不过Memcache还可用于缓存其他东西，例如图片、视频等。
- Memcache仅支持`key-value结构的数据类型`；Redis不仅仅支持简单的`key-value类型的数据`，同时还提供list、set、hash等数据结构的存储。
- `虚拟内存`：Redis当物理内存用完时，可以将一些很久没用到的value交换到磁盘。
- `分布式`：设定Memcache集群，利用magent做一主多从；Redis可以做一主多从，也可以一主一从。
- `存储数据安全`：Memcache挂掉后，数据没了；Redis可以定期保存到磁盘（持久化操作）。
- `单个value大小`：Memcache的单个value`最大1m`；Redis的单个value`最大512m`。
- `灾难恢复`：Memcache挂掉后，数据不可恢复；Redis数据丢失后可以通过` AOF `恢复。
- Redis原生就支持集群模式，Redis3.0版本中，官方便能支持Cluster模式了；Memcache没有原生的集群模式，需要依赖客户端来实现，然后往集群中分片写入数据。
- `网络模型`：`Memcache网络IO模型是多线程，非阻塞IO复用的网络模型`，原型上接近于Nginx。而`Redis使用单线程的IO复用模型`，自己封装了一个简单的AeEvent事件处理框架，主要实现类epoll、kqueue和select，更接近于Apache早期的模式。

## 5、为什么Redis单线程模型效率也能那么高？

Redis的单线程主要指的是`[接收客户端请求 -> 解析请求 -> 进行数据读写等操作 -> 发送数据给客户端]`这个过程是由一个线程（主线程）来完成的。Redis的`网络IO和键值对读写`是由该线程完成的。

- C语言实现，效率高
- 纯`内存操作`
- 基于`非阻塞的IO复用模型机制`
- 单线程的话就能`避免多线程的频繁上下文切换问题`
- `丰富的数据结构`（采用hash结构，读取速度非常快，对数据存储进行了一些优化，比如压缩表，跳表等）



- Redis的大部分操作都在**内存中完成**，并且采用了高效的数据结构。Redis瓶颈可能是机器的内存或者网络宽带。
- 采用单线程模型可以避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。
- Redis采用了I/O多路复用机制处理大量的客户端 Socket请求。IO多路复用机制是指一个线程处理多个IO流

## 6、说说Redis的线程模型？

Redis内部使用`文件事件处理器`，这个`文件事件处理器是单线程的`。采用`IO多路复用机制`同时监听多个`socket`，根据`socket`上的事件来选择对应的`事件处理器`进行处理。

文件事件处理器包含四部分：

1. `多个socket`。
2. `IO多路复用机制`。
3. `文件事件分派器`。
4. `事件处理器`（连接应答处理器、命令请求处理器、命令回复处理器）。

多个socket可能会并发产生不同的操作，每个操作对应不同的文件事件，但是IO多路复用程序会监听多个socket，会将socket产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。

![image-20220723104453165](https://knowledgeimagebed.oss-cn-hangzhou.aliyuncs.com/img/202207231045246.png)

**客户端与Redis通信一次的流程：**

1. 客户端Socket01向Redis的Server Socket请求建立连接，此时Server Socket会产生一个AE_READABLE事件，IO多路复用程序监听到Server Socket产生的事件后，将该事件压入队列中。文件事件分派器从队列中获取该事件，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的Socket01，并将该Socket01的AE_READABLE事件与命令请求处理器关联。
2. 假设此时客户端发送了一个 set key value请求，此时Redis中的Socket01会产生AE_READABLE事件，IO多路复用程序将事件压入队列，此时事件分派器从队列中获取到该事件，由于前面Socket01的AE_READABLE事件已经与命令请求处理器关联。因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取Socket01的set key value并在自己内存中完成set key value的设置。操作完成后，它会将Socket01的AE_READABLE事件与命令回复处理器关联。
3. 如果此时客户端准备好接收返回结果了，那么Redis中的Socket01会产生AE_READABLE事件，同样压入队列中，事件分派器找到相关联的命令回复处理器。由命令回复处理器对Socket01输入本次操作的一个结果，比如ok，之后解除Socket01的AE_READABLE事件与命令回复处理器的关联。





![redis单线程模型.drawio](https://knowledgeimagebed.oss-cn-hangzhou.aliyuncs.com/img/202207251416416.webp)

蓝色部分是一个事件循环，由主线程负责，可以看到`网络I/O和命令处理`都是单线程。Redis初始化时：

1. 调用` epoll_create() `创建一个 epoll 对象和调用 socket() 一个服务端 socket。
2. 调用` bind() `绑定端口和调用` listen() `监听该 socket。
3. 调用` epoll_ctl() `将` listem socket `加入到 epoll，同时**注册连接事件**处理函数。

在初始化完成后，主线程就会进入到一个`事件循环函数`中

1. 首先，会调用处理发送队列函数，看发送队列里是否有任务，如果有发送任务，则通过` write `函数将客户端发送缓存区里的数据发送出去。如果这一轮数据没有发送完，就会注册写事件处理函数，等待` epoll_wait `发现可写后再处理。
2. 接着，调用` epoll_wait `函数等待事件的到来：
   1. 如果是**连接事件**到来，则会调用连接事件处理函数，该函数的作用：调用 accept 获取已连接的 socket -> 调用 epoll_ctl将已连接的 socket 加入到 epoll -> 注册读事件处理函数。
   2. 如果是**读事件**到来，则会调用读事件处理函数，该函数的作用：调用 read 获取客户端发送的数据 -> 解析命令 -> 处理命令 -> 将客户端对象添加到发送队列中 -> 将执行结果写到发送缓存区等待发送。
   3. 如果是**写事件**到来，则会调用写事件处理函数，该函数的作用：通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会继续注册写事件处理函数，等待 epoll_wait 发现可写后再去处理。

## 7、为什么Redis需要把所有数据放到内存中？

Redis将数据放在内存中有一个好处，可以`实现最快的对数据读取`。如果数据存储在硬盘中，`磁盘I/O`会严重影响Redis的性能。且Redis还提供了`数据持久化功能`，不用担心服务器重启对内存中数据的影响。

## 8、说说Redis的同步机制？

Redis支持主从同步、从从同步。如果是第一次进行主从，主节点需要使用bgsave命令，再将后续修改操作记录到内存的缓冲区，等RDB文件全部同步到复制节点，复制节点接收完成后将RDB镜像记载到内存中。等加载完成后，复制节点通知主节点将复制期间修改的操作记录同步到复制节点，即可完成同步过程。



redis的主从同步机制可以确保redis的master和slave之间的数据同步。同步方式包括`全量复制`和`增量复制`。

#### 全量拷贝

![image-20220723161923695](https://knowledgeimagebed.oss-cn-hangzhou.aliyuncs.com/img/202207231707716.png)

1. `Slave`第一次启动时，连接`Master`，发送`psync`命令，格式为` psync {runId} {offset}`

   > `{runId}` 为master的`运行id`；`{offset}`为slave自己的`复制偏移量`。
   > slave第一次连接master时，slave并不知道master的runId，也不知道自己偏移量，这时候slave会传一个问号和-1，告诉master节点是`第一次同步`。
   >
   > 格式为`psync ? -1`

2. 当`master`接收到 `psync ? -1` 时，知道slave是要`全量复制`，就会将自己的` runId `和` offset `告知` slave `，回复命令` fullresync {runId} {offset} `。同时，master会执行bgsave命令来生成rdb文件，期间的所有写命令将被写入缓冲区。

   > slave接受到master的回复命令后，会保存master的runId和offset，slave此时处于同步状态。
   > slave处于同步状态，如果此时收到请求，当配置参数`slave-server-stale-data yes`时，会响应当前请求；`slave-server-stale-data no`，返回错误。

3. master `bgsave`执行完毕，向slave发送rdb文件。rdb文件发送完毕后，开始向slave发送缓冲区中的写命令。

4. slave收到rdb文件后，丢弃所有旧数据，开始载入rdb文件。

5. rdb文件同步结束之后，slave执行从master缓冲区发送过来的所有写命令。

6. 此后` master `每执行一个写命令，就向slave发送相同的写命令。

#### 增量拷贝

1. 如果出现`网络闪断`或者`命令丢失异常情况`时，当主从连接恢复后，由于从节点之前保存了自身已复制的`偏移量`和主节点的`运行ID`。因此会把它们当做`psync参数`发送给主节点，要求进行`部分复制操作`。格式为` psync {runId} {offset}`。
2. 主节点接到`psync`命令后首先核对参数runId是否与自身一致。如果一致，说明之前复制的是当前主节点，之后根据参数offset在自身复制积压缓冲区查找，如果偏移量之后的数据存在缓冲区中，则对从节点发送` +continue`响应，表示可以进行部分复制；否则进行全量复制。
3. 主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态。

**同步故障处理**

1. **拷贝超时**

   对于`数据量较大`的主节点，比如生成的rdb文件超过6GB以上时要格外小心。传输文件这一步操作非常耗时，速度取决于`主从节点之间网络带宽`，通过细致分析` full resync `和` master slave `这两行日志的时间差，可以算出rdb文件从创建到传输完毕消耗的总时间。如果总时间超过了` repl-timeout `所配置的值（默认60秒），从节点将放弃接受rdb文件并清理已经下载的临时文件，导致全量复制失败。

   针对数据量较大的节点，建议**调大 repl-timeout 参数防止出现全量同步数据超时**。

2. **积压缓冲区拷贝溢出**

   slave节点`从开始接收rdb文件`到`接收完成`期间，主节点仍然响应读写命令，因此主节点会把这期间`写入命令`保存在`复制积压缓冲区`内，当从节点加载完rdb文件后，主节点再把缓冲区的数据发送给从节点，**保证主从数据一致性**。

   如果主节点创建和传输RDB的时间过长，对于高流量写入场景非常容易造成主节点复制客户端缓冲区溢出。默认配置为`client-output-buffer-limit slave 256MB 64MB 60`，如果60秒内缓冲区消耗**持续大于64MB或者直接超过256MB时**，主节点将直接关闭复制客户端连接，造成全量同步失败。

   因此，运维人员需要根据主节点数据量和写命令并发量调整client-output-buffer-limit slave配置，避免全量复制期间客户端缓冲区溢出。对于主节点，当发送完所有的数据后就认为全量复制完成，打印成功日志：synchronization with slave127.0.0.1：6380 succeeded

3. **slave全量同步的响应问题**

   - `slave`节点接收完主节点传送来的全部数据后会`清空自身旧数据`，执行`flash old data`，然后加载rdb文件。对于较大的rdb文件，这一步操作依然比较耗时。

   - 对于线上做读写分离的场景，从节点也负责响应读命令，如果slave节点正出于全量复制阶段，那么slave节点在响应读命令可能拿到过期或错误的数据。对于这种场景，redis复制提供了slave-server-stale-data yes参数（默认开启），如果开启则slave节点依然响应所有命令。对于无法容忍不一致的应用场景可以设置no来关闭命令执行，此时从节点除了info和slaveof命令之外所有的命令只返回sync with master in progress信息。

**节点运行Id**

1. 每个Redis节点启动后，都会动态分配一个40位的十六进制字符串作为运行ID，即`{runId}`。

   > 运行ID的主要作用是用来唯一识别Redis节点，比如从节点保存主节点的运行ID识别自己正在复制的是哪个主节点。

2. 如果只使用`ip+port`的方式识别主节点，那么主节点重启变更了整体数据集（如替换rdb/aof文件），从节点再基于偏移量复制数据将是不安全的，因此当运行ID变化后从节点将做全量复制。

3. 可以运行info server命令查看当前节点的运行ID。

**偏移量拷贝**

1. 参与复制的主从节点都会维护`自身复制偏移量`，即`{offset}`。
2. 主节点（master）在处理完写入命令后，会把`命令的字节长度做累加记录`，统计信息在`info relication中的 master_repl_offset 指标中`。
3. 从节点（slave）在接收到主节点发送的命令后，也会`累加记录自身的偏移量`，统计信息在`info relication命令的slave_repl_offset指标中`。
4. 从节点（slave）每秒钟上报自身的复制偏移量给主节点，因此主节点也会保存从节点的复制偏移量。

**积压缓冲区拷贝**

1. 存在于主节点（master），默认大小为1MB，可以通过参数` rel_backlog_size `来修改默认大小。
2. 复制积压缓冲区是保存在主节点上的一个固定长度的队列。当从节点（slave）连接主节点时被创建，这时主节点（master）响应写命令时，不但会把命令发送给从节点，还会写入复制积压缓冲区。
3. 由于缓冲区本质上是`先进先出（FIFO）`的`定长队列`，所以能实现保存最近已复制数据的功能，用于部分复制和复制命令丢失的数据补救。复制缓冲区相关统计信息可以通过主节点的` info replication `命令查看。

## 9、pipeline有什么好处？为什么要用pipeline？

使用`pipeline（管道）`的好处在于可以将`多次I/O往返的时间缩短为一次`，但是要求管道中执行的指令间没有因果关系。

用pipeline的原因在于可以实现请求/响应服务器的功能，当客户端未读取旧响应时，它也可以处理新的请求。如果客户端存在多个命令发送到服务器时，那么客户端无需等待服务端的每次响应才能执行下个命令，只需最后一步从服务端读取回复即可。

## 10、说说Redis有什么优点和缺点？

**优点：**

- 速度快：因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)。
- 支持丰富的数据结构：支持String、list、set、zset、hash五种基础的数据结构。
- 持久化存储：Redis提供RDB和AOF两种数据的持久化存储方案，解决内存数据库最担心的万一Redis挂掉，数据会消失掉。
- 高可用：内置Redis Sentinel，提供高可用方案，实现主从故障自动转移。内置Redis Cluster，提供集群方案，实现基于槽的分片方案，从而支持更大的Redis规模。
- 丰富的特性：Key过期、计数、分布式锁、消息队列等。

**缺点：**

- 由于Redis是内存数据库，所以，单台机器，存储的数据量，跟机器本身的内存大小有关。虽然Redis本身有Key过期策略，但是还是需要提前预估和节约内存。如果内存增长过快，需要定期删除数据。
- 如果进行完整重同步，由于需要生成RDB文件，并进行传输，会占用主机的CPU，并会消耗现网的带宽。在Redis2.8版本中，已经有部分重同步的功能，但是还是有可能有完整重同步的。比如新上线的备机。
- 修改配置文件，进行重启，将硬盘中的数据加载进内存，时间比较久。在这个过程中，Redis不能提供服务。

## 11、Redis缓存刷新策略有哪些？

- LRU/LFU/FIFO算法剔除：当Redis memory达到最大值的时候，首先关注的是过期的数据，通过删除策略来达到保护内存的效果。这种方式只需要关注缓存的策略配置，不需要关心具体的每一个key到底是怎么过期的，每一个key到底是怎么被删除的。
- 超时剔除：设置过期时间
- 主动更新：开发控制生命周期

## 12、Redis持久化方式有哪些？以及有什么区别？

Redis提供两种持久化机制RDB和AOF。

### RDB持久化机制

是指用`数据集快照的方式半持久化模式`记录Redis数据库的所有键值对，在某个时间点将数据写入一个临时文件，持久化结束后，用这个临时文件替换上传持久化的文件。达到数据恢复。

**优点：**

- 只有一个文件dump.rdb，`方便持久化`。
- `容灾性好`，一个文件可以保存到安全的磁盘。
- `性能最大化`，`fork`子进程来完成`写`操作，让主进程继续处理命令，所以是`IO最大化`。使用单独子进程来进行持久化，主进程不会进行任何IO操作，保证了Redis的高性能。
- 相对于数据集大时，比AOF的启动效率更高。

**缺点：**

数据安全性低。RDB是间隔一段时间进行持久化，如果持久化之间Redis发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候。

### AOF=Append-only file持久化方式

是指`所有的命令行记录`以Redis命令请求协议的格式`完全持久化存储`，保存为AOF文件。

**优点：**

- 数据安全，`AOF持久化`可以配置`appendfsync`属性，有`always`，每进行一次命令操作就记录到AOF文件中一次。
- 通过append模式写文件，即使途中服务器宕机，可以通过`redis-check-aof`工具解决`数据一致性问题`。
- AOF机制的`rewrite`模式。AOF文件没被rewrite之前（文件过大时会对命令进行合并重写），可以删除其中的某些命令（比如误操作的flushall）

**缺点：**

- AOF文件比RDB文件大，且恢复速度慢。
- 数据集大的时候，比RDB启动效率低。

## 13、怎么样选择持久化？

- 不要仅仅使用RDB，因为那样会导致丢失很多数据。
- 也不要仅仅使用AOF，因为那样有两个问题，第一：`通过AOF做冷备没有RDB做冷备的恢复速度更快`。第二：`RDB每次简单粗暴生成数据快照，更加健壮`，可以避免AOF这种复杂的备份和恢复机制的bug。
- Redis支持同时开启两种持久化方式，可以综合使用AOF和RDB两种持久化机制，用`AOF来保证数据不丢失`，作为数据恢复的第一选择；用`RDB来做不同程度的冷备`，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复。
- 如果同时使用RDB和AOF两种持久化机制，那么在Redis重启的时候，会使用AOF来重新构建数据，因为AOF中的数据更加完整。

## 14、怎么使用Redis实现消息队列？

一般使用`lsit`结构作为队列，`rpush`生产消息，`lpop`消费消息。当lpop没有消息的时候，要适当`sleep`一会再重试。

- 可不可以不用sleep？list还有个指令叫`blpop`，在没有消息的时候，会阻塞住直到消息的到来。
- 能不能生产一次消费多次？使用`pub/sub主题订阅者模式`，可以实现`1：N的消息队列`。
- pub/sub有什么缺点？在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列（RabbitMQ）等。
- Redis如何实现延时队列？使用`zset（sortedset）`，拿`时间戳作为score（权重）`，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。

## 15、说说对Redis事务的理解？

### 什么是Redis事务？原理是什么？

`Redis`中的事务是`一组命令的集合`，是`Redis`的最`小执行单位`。它可以保证`一次执行多个命令`，每个事务是一个单独的`隔离操作`，事务中的所有命令都会`序列化`、`按顺序地执行`。服务端在执行事务的过程中，不会被其他客户端发送来的命令请求打断。

原理是**先将属于一个事务的命令发送给Redis，然后依次执行这些命令**。

### Redis事务的注意点有哪些？

- Redis事务是`不支持回滚`的，不像Mysql的事务一样，要么都执行要么都不执行。
- Redis服务端在执行事务的过程中，不会被其他客户端发送来的命令`请求打断`。直到事务命令全部执行完毕才会执行其他客户端的命令。

### Redis事务为什么不支持回滚？

Redis的事务不支持回滚，但是执行的命令有`语法错误`，Redis会执行失败。这些问题可以从程序层面捕获并解决。但是如果出现其他问题，则依然会继续执行余下的命令。如此做的原因是因为回滚需要增加很多工作，而**不支持回滚则可以保持简单、快速的特性**。

## 16、Redis为什么设计成单线程的？

多线程处理会涉及到锁，并且多线程处理会涉及到线程切换而消耗CPU。采用单线程，`避免了不必要的上下文切换`和`竞争条件`。其次CPU不是Redis的瓶颈，Redis的瓶颈最有可能是`机器内存`或者`网络带宽`。

## 17、什么是bigkey？会存在什么影响？

bigkey是指键值占用内存空间非常大的key。例如一个字符串a存储了200M的数据。

bigkey的主要影响有：

- 网络阻塞：获取bigkey时，传输的数据量比较大，会增加带宽的压力。
- 超时阻塞：因为bigkey占用的空间比较大，所以操作起来效率会比较低，导致出现阻塞的可能性增加。
- 导致内存空间不平衡：一个bigkey存储数据量比较大，同一个key在同一个节点或服务器中存储，会造成一定影响。

## 18、熟悉哪些Redis集群模式？

1. **Redis Sentinel**

   体量较小时，选择 Redis Sentinel ，单主 Redis 足以支撑业务。

2. **Redis Cluster**

   Redis 官方提供的集群化方案，体量较大时，选择 Redis Cluster ，通过分片，使用更多内存。

3. **Twemprox**

   Twemprox 是 Twtter 开源的一个 Redis 和 Memcached 代理服务器，主要用于管理 Redis 和Memcached 集群，减少与Cache 服务器直接连接的数量。

4. **Codis**

   Codis 是一个代理中间件，当客户端向 Codis 发送指令时， Codis 负责将指令转发到后面的Redis 来执行，并将结果返回给客户端。一个 Codis 实例可以连接多个 Redis 实例，也可以启动多个 Codis 实例来支撑，每个 Codis 节点都是对等的，这样可以增加整体的 QPS 需求，还能起到容灾功能。

5. **客户端分片**

   在 Redis Cluster 还没出现之前使用较多，现在基本很少热你使用了，在业务代码层实现，起几个毫无关联的 Redis 实例，在代码层，对 Key 进行 hash 计算，然后去对应的 Redis 实例操作数据。这种方式对 hash 层代码要求比较高，考虑部分包括，节点失效后的替代算法方案，数据震荡后的自动脚本恢复，实例的监控，等等。

## 19、是否使用过Redis Cluster集群？集群的原理是什么？

- 所有的节点相互连接
- 集群消息通信通过集群总线通信，集群总线端口大小为客户端服务端口 + 10000（固定值）
- 节点与节点之间通过二进制协议进行通信
- 客户端与集群节点之间通信和通常一样，通过文本协议进行
- 集群节点不会代理查询
- 数据按照Slot存储分布在多个Redis实例上
- 集群节点挂掉会自动故障转移
- 可以相对平滑扩/缩容节点

Redis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value 时，redis 先对key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号，在 0~16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点。

## 20、Redis常见性能问题和解决方案有哪些？

- Master节点最好不要做任何持久化工作，如RDB内存快照和AOF日志文件。
- 如果数据比较重要，某个slave节点开启AOF备份数据，策略设置为每秒同步一次。
- 为了主从复制的速度和连接的稳定性，Master节点和Slave节点最好在同一个局域网中。
- 尽量避免在压力很大的主库上增加从库。
- 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master <- Slave1 <- Slave2 <- Slave3...；这样的结构方便解决单点故障问题，实现了Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。

## 21、假如 Redis 里面有 1 亿个 key，其中有 10w 个 key 是以某个固定的已知的前缀开头的，如果将它们全部找出来？

我们可以使用` keys `命令和` scan `命令，但是会发现使用 scan 更好。

1. **使用 keys 命令**

   直接使用 keys 命令查询，但是如果是在生产环境下使用会出现一个问题，keys 命令是遍历查询的，查询的时间复杂度为 O(n)，数据量越大查询时间越长。而且 Redis 是单线程，keys 指令会导致线程阻塞一段时间，会导致线上 Redis 停顿一段时间，直到 keys 执行完毕才能恢复。这在生产环境是不允许的。除此之外，需要注意的是，这个命令没有分页功能，会一次性查询出所有符合条件的 key 值，会发现查询结果非常大，输出的信息非常多。所以不推荐使用这个命令。

2. **使用 scan 命令**

   scan 命令可以实现和 keys 一样的匹配功能，但是 scan 命令在执行的过程不会阻塞线程，并且查找的数据可能存在重复，需要客户端操作去重。因为 scan 是通过游标方式查询的，所以不会导致Redis 出现假死的问题。Redis 查询过程中会把游标返回给客户端，单次返回空值且游标不为 0，则说明遍历还没结束，客户端继续遍历查询。scan 在检索的过程中，被删除的元素是不会被查询出来的，但是如果在迭代过程中有元素被修改，scan 不能保证查询出对应元素。相对来说，scan 指令查找花费的时间会比 keys 指令长。

## 22、什么情况下会导致Redis阻塞？

Redis产生阻塞的原因主要有内部和外部两个原因导致

**内部原因**

- 如果Redis主机的CPU负载过高，也会导致系统崩溃。
- 数据持久化占用资源过多。
- 对Redis的API或指令使用部合理，导致Redis出现问题。

**外部原因**

外部原因主要是服务器的原因，例如服务器的CPU线程在切换过程中竞争过大，内存出现问题、网络问题等。

## 23、缓存和数据库谁先更新？

1. 写请求过来，将写请求缓存到缓存队列中，并且开始执行写请求的具体操作（删除缓存中的数据，更新数据库，更新缓存）。
2. 如果在更新数据库过程中，又来个读请求，将读请求再次存入到缓存队列（可以搞n个队列，采用key的hash值进行队列个数取模hash%n，落到对应的队列中，队列需要保证顺序性）中，顺序性保证等待队列前的写请求执行完成，才会执行读请求之前的写请求删除缓存失败。直接返回，此时数据库中的数据是旧值，并且与缓存中的数据是一致的，不会出现缓存一致性的问题。
3. 写请求删除缓存成功，则更新数据库，如果更新数据库失败，则直接返回，写请求结束，此时数据库中的值依旧是旧值。读请求过来后，发现缓存中没有数据，则会直接像数据库中请求，同时将数据写入到缓存中，此时也不会出现数据一致性的问题。
4. 更新数据成功之后，再更新缓存，如果此时更新缓存失败，则缓存中没有数据，数据库中是新值，写请求结束，此时读请求还是一样，发现缓存中没有数据，同样会从数据库中读取数据，并且存入到缓存中，其实这里不管更新缓存成功还是失败，都不会出现缓存一致性的问题。

主要使用串行化，每次操作进来必须按照顺序进行。如果某个队列元素积压太多，可以针对读请求进行过滤，提示用户刷新页面，重新请求。

**潜在的问题**

- 请求时间过长，大量的写请求堆压在队列中，一个读请求得等到都写完了才可以获取数据。
- 读请求并发高。
- 热点数据路由问题，导致请求倾斜。

## 24、怎么提高缓存命中率？

- 提前加载数据到缓存中
- 增加缓存的存储空间，提高缓存的数据
- 调整缓存的存储数据类型
- 提高缓存的更新频率

## 25、说说Redis的持久化机制？

Redis是一个支持`持久化`的`内存数据库`，通过持久化机制把内存中的数据同步到硬盘文件来保证`数据持久化`。当Redis重启后通过把硬盘文件重新加载到内存，就能达到恢复数据的目的。

**实现：**单独`创建fork()`一个`子进程`，**将当前父进程的数据库数据复制到子进程的内存中**，然后由`子进程`写入到`临时文件`中，持久化的过程结束后，再用这个临时文件替换上传的快照文件，然后子进程退出，内存释放。

**RDB持久化机制**是Redis默认的持久化方式。按照`一定的时间周期策略`把内存的数据以`快照`的形式保存到`硬盘的二进制文件`，即`Snapshot快照存储`，对应产生的数据文件为dump.rdb，通过配置文件中的`save参数`来定义`快照的周期`。（快照可以是其所表示的数据的一个副本，也可以是数据的一个复制品）

**AOF持久化机制**：Redis会将每一个收到的`写命令`通过`Write函数追加到文件`最后，类似于`Mysql的binlog`。当Redis重启是会通过`重新执行文件中保存的命令`来在内存中重建整个数据库的内容。

当这两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。

## 26、热点数据和冷数据是什么？

**热点数据，缓存才有价值** 对于冷数据而言，大部分数据可能还没有再次访问到就已经被挤出内存，不仅占用内存，而且价值不大。频繁修改的数据，看情况考虑使用缓存 对于上面两个例子，寿星列表、导航信息都存在一个特点，就是信息修改频率不高，读取通常非常高的场景。 对于热点数据，比如我们的某IM产品，生日祝福模块，当天的寿星列表，缓存以后可能读取数十万次。再举个例子，某导航产品，我们将导航信息，缓存以后可能读取数百万次。 **数据更新前至少读取两次，**缓存才有意义。这个是最基本的策略，如果缓存还没有起作用就失效了，那就没有太大价值了。 那存不存在，修改频率很高，但是又不得不考虑缓存的场景呢？有！比如，这个读取接口对数据库的压力很大，但是又是热点数据，这个时候就需要考虑通过缓存手段，减少数据库的压力，比如我们的某助手产品的，点赞数，收藏数，分享数等是非常典型的热点数据，但是又不断变化，此时就需要将数据同步保存到Redis缓存，减少数据库压力。

## 27、Redis的数据类型，以及每种数据类型的使用场景？

1. **String：**最常规的set/get操作，Value可以是字符串、整数或浮点数。对整个字符串或字符串的一部分进行操作；对整数或浮点数进行自增或自减操作。**应用场景：**缓存对象、常规计数、分布式锁、共享Session等。
2. **hash：**包含键值对的无序散列表，比较方便的就是操作其中的某个字段。博主在做单点登录的时候，就是用这种数据结构存储用户信息，以cookieId作为key，设置30分钟为缓存过期时间，能很好的模拟出类似session的效果。**应用场景：**缓存对象、购物车等。 
3. **list：**一个链表，链表上的每个节点都包含一个字符串。使用List的数据结构，可以做简单的消息队列的功能。另外还有一个就是，可以利用lrange命令，做基于redis的分页功能，性能极佳，用户体验好。本人还用一个场景，很合适—取行情信息。就也是个生产者和消费者的场景。LIST可以很好的完成排队，先进先出的原则。 **应用场景：**消息队列（问题：1、生产者需要自行实现全局唯一ID；2、不能以消费组形式消费数据等）
4. **set：**包含字符串的无序集合。因为`set`堆放的是一堆`不重复值`的集合。所以可以做全局去重的功能。为什么不用JVM自带的Set进行去重？因为我们的系统一般都是集群部署，使用JVM自带的Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务，太麻烦了。 另外，就是利用交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。**应用场景：**聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。
5. **Zset：** Zset（sorted set）多了一个权重参数score,集合中的元素能够按score进行排列。和散列一样，用于存储键值对。字符串成员与浮点数分数之间的有序映射；元素的排列顺序由分数的大小绝对；包含方法有添加、获取、删除单个元素以及根据分值范围或成员来获取元素。**应用场景：**排序、比如排行榜、电话和姓名排序等。

**Redis后续版本支持的四种数据类型**

- **BitMap（2.2版新增）：**二值状态统计的场景，比如签到、判断用户登录状态、连续签到用户总数等。
- **HyperLogLog（2.8版新增）：**海量数据基数统计的场景，比如百万级网页UV计数等。
- **GEO（3.2版新增）：**存储地理位置信息的场景，比如滴滴叫车。
- **Stream（5.0版新增）：**消息队列，相比于基于list类型实现的消息队列，有这两个特有的特性：自动生成全局唯一的消息ID，支持以消费组形式消费数据。

## 30、Redis的过期策略以及内存淘汰机制？

Redis采用的是`定期删除`+`惰性删除策略`。

为什么不用`定时删除策略`？定时删除，用一个定时器来负责监视key，过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key，因此没有采用这一策略。

**定期删除+惰性删除是如何工作的呢？**定期删除，redis默认`每隔100ms`检查一次，是否有过期的key，有过期key则删除。并且redis不是每隔100ms将`所有的key检查一次`，而随机抽取进行检查。但是如果仅仅使用定期删除策略，会导致很多key到时间没有删除。于是惰性删除就派上用处了，在获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。这种机制就没有问题了吗？不是的，如果定期删除机制没删除key，并且也没有即时去请求key。这样，redis的内存会越来越高。那么就应该采用内存淘汰机制。在redis.conf中有一行配置

```
maxmemory-policy volatile-lru
```

- **volatile-lru**：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 
- **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 
- **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 
- **allkeys-lru**：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 
- **allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰
- **no-enviction**（驱逐）：禁止驱逐数据，新写入操作会报错 ps：如果没有设置 expire 的key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。

## 31、为什么用Redis作为MySQL的缓存？

主要是因为Redis具备[高性能]和[高并发]两种特性。

1. **Redis具备高性能**

   用户第一次访问MySQL中的某些数据。这个过程会比较缓慢，因为是从硬盘上读取的。将该用户访问的数据缓存在Redis中，下次访问就可以直接从缓存中获取了，操作Redis缓存就是直接操作内存，所以速度相当快。

2. **Redis具备高并发**

   单台设备的Redis的QPS（每秒钟处理完请求的次数）是MySQL的10倍，Redis单机的QPS能轻松破10W，而MySQL单机的QPS很难破1W。所以，直接访问Redis能够承受的请求是远远大于直接访问MySQL的，可以考虑把数据库中的部分数据转移到缓存中，这样用户的一部分请求会直接命中缓存而不用经过数据库。

## 32、Redis的五种数据类型是如何实现的？

![image-20220725104942930](https://knowledgeimagebed.oss-cn-hangzhou.aliyuncs.com/img/202207251049925.png)

> String类型内部实现

String类型的底层的数据结构实现主要是**SDS（简单动态字符串）**。SDS相比于C的原生字符串：

- `SDS不仅可以保存文本数据，还可以保存二进制数据`。因为SDS使用`len属性`的值而不是空字符来判断字符串是否结束，并且SDS的所有API都会以处理二进制的方式来处理SDS存放在buf[]数组里的数据。所以SDS不仅能存放文本数据，而且能保存图片、音频、视频、压缩文件这样的二进制数据。
- `SDS获取字符长度的时间复杂度是O(1)`。因为C语言的字符串并不记录自身长度，所以获取长度的复杂度为O(n)。而SDS结构里用len属性记录了字符串长度，所以复杂度为O(1)。
- `Redis的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出`。因为SDS在拼接字符串之前会检查SDS空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。

> List类型内部实现

List类型的底层数据结构是由**双向链表或压缩列表**实现的。

- 如果列表的元素个数小于` 512 `个（默认值，可由list-max-ziplist-entries配置），列表每个元素的值都小于` 64 字节`（默认值，可由list-max-ziplist-value配置），Redis会使用`压缩列表`作为List类型的底层数据结构。(元素个数小于512个，列表中每个元素的值都小于64字节，使用`压缩列表`)
- 如果列表的元素不满足上面的条件，Redis会使用`双向链表`作为List类型的底层数据结构。(正常情况下，使用`双向链表`)

在Redis3.2版本之后，List数据类型底层数据结构就只由`quicklist`实现了，替代了双向链表和压缩列表。(现在，list的底层数据结构使用`quicklist`实现)

> Hash类型内部实现

Hash类型的底层数据是由**压缩列表或哈希表**实现的。

- 如果哈希元素个数小于` 512个 `（默认值，可由hash-max-ziplist-entries配置），所有值`小于 64 字节`（默认值，可由hash-max-ziplist-value配置）的话，Redis会使用`压缩列表`作为Hash类型的底层数据结构。(哈希元素小于 512 个，所有值小于 64 字节，使用`压缩列表`)
- 如果哈希类型元素不满足上面条件，Redis会使用`哈希表`作为Hash类型的底层数据结构。(平时使用`哈希表`)

在Redis7.0中，压缩列表数据结构已经废弃了，交由`listpack数据结构`来实现了。(现在，Hash的底层数据结构使用`listpack`)

> Set类型内部实现

Set类型的底层数据结构是由**哈希表或整数集合**实现的。

- 如果集合中的元素都是整数且元素个数小于 512 （默认值，set-maxintset-entries配置）个，Redis 会使用`整数集合`作为 Set 类型的底层数据结构；
- 如果集合中的元素不满足上面条件，则 Redis 使用`哈希表`作为 Set 类型的底层数据结构。

> ZSet类型内部实现

Zset类型的底层数据结构是由**压缩列表或跳表**来实现的。

- 如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis会使用`压缩列表`作为Zset类型的底层数据结构。
- 如果有序集合的元素不满足上面的条件，Redis会使用`跳表`作为Zset类型的底层数据结构。

在Redis7.0中，压缩列表数据结构就已经废弃了，交由` listpack `数据结构来实现了。